{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd077d6590aaf3df8e18e257d25dcb04f449449bd4d887ac6d65a10ad2a765160c4",
   "display_name": "Python 3.9.1  ('.bankruptcy': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "77d6590aaf3df8e18e257d25dcb04f449449bd4d887ac6d65a10ad2a765160c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "if \"multiCollinearityEliminator\" in sys.modules: \n",
    "    reload(sys.modules[\"multiCollinearityEliminator\"])\n",
    "from multiCollinearityEliminator import MultiCollinearityEliminator\n",
    "\n",
    "if \"visualizations\" in sys.modules: \n",
    "    reload(sys.modules[\"visualizations\"])\n",
    "else:\n",
    "    import visualizations\n",
    "vis = visualizations.Visualizations()\n",
    "\n",
    "if \"modelling\" in sys.modules: \n",
    "    reload(sys.modules[\"modelling\"])\n",
    "else:\n",
    "    import modelling\n",
    "mod = modelling.Modelling(vis=vis)\n",
    "\n",
    "RANDOM_SEED = 1243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRemovedColumns(oldDF, newDF):\n",
    "    return ([col for col in oldDF.columns if col not in newDF.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = pd.read_csv(\"data/data.csv\")\n",
    "print(\"Size of the raw data: %s\" % str(rawData.shape))\n",
    "rawData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are %d null values in the raw data.\" % (rawData.isnull().values.sum()))\n",
    "rawData.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plotCounts(xData=rawData[\"Bankrupt?\"], figSize=(6,5), plotTitle=\"Class Distributions \\n (0: Stable || 1: Bankrupt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plotHistograms(data=rawData, bins=50, figSize=(35,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plotBoxPlots(data=rawData, figSize=(35,30), plotTitle=\"Raw Data Boxplots\")"
   ]
  },
  {
   "source": [
    "## Steps for data cleaning\n",
    "\n",
    "1. Split the data into training/ test sets\n",
    "2. Remove highly correlated columns\n",
    "3. Remove row-wise outliers\n",
    "4. Normalize the data column-wise (center/ scale)\n",
    "5. Remove zero/ low variance columns\n",
    "6. Replicate all the steps on the test set\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = rawData.iloc[:, 1:]\n",
    "y_raw = rawData.iloc[:, 0]\n",
    "TARGET_COL = y_raw.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw_train, X_raw_test, y_raw_train, y_raw_test = [df.reset_index(drop=True) for df in \\\n",
    "    train_test_split(X_raw, y_raw, test_size=0.2, stratify=y_raw, random_state=RANDOM_SEED)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plotCorrelationMatrix(data=X_raw_train, figSize=(25,20), plotTitle=\"Correlation Heatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRELATION_THRESH = 0.95\n",
    "mce = MultiCollinearityEliminator(pd.concat([y_raw_train, X_raw_train], axis=1), TARGET_COL, CORRELATION_THRESH)\n",
    "X_no_corrs_train = mce.autoEliminateMulticollinearity()\n",
    "X_no_corrs_train.drop(columns=TARGET_COL, inplace=True)\n",
    "\n",
    "highCorrColumns = getRemovedColumns(oldDF=X_raw_train, newDF=X_no_corrs_train)\n",
    "print(\"%d columns were dropped due to high correlation.\" % len(highCorrColumns))\n",
    "print(highCorrColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlierModel = LocalOutlierFactor(n_neighbors=100, metric=\"manhattan\", contamination=0.05)\n",
    "outlierPreds = outlierModel.fit_predict(X_no_corrs_train)\n",
    "outlierTrainIndex = np.where(outlierPreds == -1)[0]\n",
    "X_no_outliers_train = X_no_corrs_train.drop(outlierTrainIndex, axis=0)\n",
    "y_train = y_raw_train.drop(outlierTrainIndex, axis=0)\n",
    "\n",
    "print(\"%d rows were removed due to outlier values.\" % len(outlierTrainIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plotBoxPlots(data=X_no_outliers_train, figSize=(20,20), plotTitle=\"Preprocessed Boxplots - No Outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustScalerModel = preprocessing.RobustScaler()\n",
    "X_scaled_train = robustScalerModel.fit_transform(X_no_outliers_train)\n",
    "X_scaled_train = pd.DataFrame(X_scaled_train)\n",
    "X_scaled_train.columns = X_no_outliers_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plotBoxPlots(data=X_scaled_train, figSize=(20,20), plotTitle=\"Preprocessed Boxplots - No Outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowVarianceFeatureRemover(data, thresh):\n",
    "    varModel = VarianceThreshold(threshold=thresh)\n",
    "    varModel.fit(X=data)\n",
    "    return (data[data.columns[varModel.get_support(indices=True)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANCE_THRESH = 1e-3\n",
    "X_train = lowVarianceFeatureRemover(data=X_scaled_train, thresh=VARIANCE_THRESH)\n",
    "lowVarCols = getRemovedColumns(oldDF=X_scaled_train, newDF=X_train)\n",
    "print(\"%d columns are removed due to low variance <= %s\" % (len(lowVarCols), str(VARIANCE_THRESH)))\n",
    "print(lowVarCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the training data: %s\" % str(X_train.shape))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_corrs_test = X_raw_test.drop(columns=highCorrColumns)\n",
    "X_scaled_test = pd.DataFrame(robustScalerModel.transform(X_no_corrs_test))\n",
    "X_scaled_test.columns = X_no_corrs_test.columns\n",
    "X_test = X_scaled_test.drop(columns=lowVarCols)\n",
    "y_test = y_raw_test\n",
    "\n",
    "print(\"Shape of the test data: %s\" % str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteModel = SMOTE(random_state=RANDOM_SEED)\n",
    "X_train_sm, y_train_sm = smoteModel.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModel = RandomForestClassifier(n_estimators=200, random_state=RANDOM_SEED)\n",
    "rfModel.fit(X_train_sm, y_train_sm)\n",
    "rfPreds = rfModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.getModelPerformance(trueVals=y_test, preds=rfPreds, figSize=(5,5), plotTitle=\"Random Forests Performance\", targetNames=[\"Stable\",\"Bankrupt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thread\n",
    "#eta\n",
    "#min_child_weight\n",
    "#max_depth\n",
    "#max_leaf_nodes\n",
    "#gamma\n",
    "#subsample\n",
    "#colsample_bytree\n",
    "\n",
    "xgbModel = xgb.XGBClassifier(\n",
    "    nrounds= 1000, max_depth=3, eta=0.1, objective=\"binary:logistic\", eval_metric=\"logloss\", \n",
    "    verbosity=0, use_label_encoder=False, random_state=RANDOM_SEED)\n",
    "xgbModel.fit(X_train_sm, y_train_sm)\n",
    "xgbPreds = xgbModel.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.getModelPerformance(trueVals=y_test, preds=xgbPreds, figSize=(5,5), plotTitle=\"XGBoost Performance\", targetNames=[\"Stable\",\"Bankrupt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(xgbModel, X_train_sm, y_train_sm, cv=5)\n",
    "print(\"Mean cross-validation score: %.2f\" % scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "kfScores = cross_val_score(xgbModel, X_train_sm, y_train_sm, cv=kfold)\n",
    "print(\"K-fold CV average score: %.2f\" % kfScores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}